{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "batch_size = 64\n",
    "num_workers = 2\n",
    "n_epoch = 100\n",
    "z_dim = 100 # 噪音向量的维度\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "ckpt_dir = 'drive/MyDrive/models'\n",
    "faces_path = \"faces\"\n",
    "\n",
    "print(\"Device: \", device) "
   ],
   "id": "16f67a8c25d5be28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "清理输出函数",
   "id": "6c51e38021ee5098"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def clear_output():\n",
    "    \"\"\"\n",
    "    清理Jupyter Notebook中的输出\n",
    "    \"\"\"\n",
    "    os.system('cls' if os.name == 'nt' else 'clear')\n",
    "    if 'ipykernel' in sys.modules:\n",
    "        from IPython.display import clear_output as clear\n",
    "        clear()"
   ],
   "id": "c86c250c1822ba34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "定义Dataset，缩放到64 * 64，并进行标准化",
   "id": "19b974c1b27567b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class CrypkoDataset(Dataset):\n",
    "    def __init__(self, img_path='./faces'):\n",
    "        self.fnames = [img_path + '/' + img for img in os.listdir(img_path)]\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((64, 64)),\n",
    "            transforms.ToTensor(),\n",
    "            # 这里将图片缩放到了均值为0.5，方差为0.5的区间，本质是执行了 (x-0.5)/0.5\n",
    "            transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "\n",
    "        self.num_samples = len(self.fnames)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.fnames[idx]\n",
    "        img = torchvision.io.read_image(fname)\n",
    "        img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ],
   "id": "a46a43a2c6445e6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = CrypkoDataset(faces_path)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ],
   "id": "7471210937108d6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dataset.__getitem__(0).size(), len(dataset)",
   "id": "a8e0ac37f2144fa7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "images = [(dataset[i] + 1) / 2 for i in range(16)]\n",
    "grid_img = torchvision.utils.make_grid(images, nrow=4)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(grid_img.permute(1, 2, 0)) # plt接收的图片通道要在最后，所以permute一下\n",
    "plt.show()"
   ],
   "id": "7c956f25c5992596",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 定义模型",
   "id": "fca0d4d7d02185b4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Generator",
   "id": "dc271bd8958d931a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    输入Shape为(N, in_dim)，N为batch_size, in_dim是随机向量的维度\n",
    "    输出Shape为(N, 3, 64, 64)，即生成N张64x64的彩色图像\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, dim = 64):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        def dconv_bn_relu(in_dim, out_dim):\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_dim, out_dim, 5, 2,\n",
    "                                   padding = 2, output_padding = 1, bias = False),\n",
    "                nn.BatchNorm2d(out_dim),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        # 1. 先用线性层将随机向量变成 dim*8 个通道，大小为4x4的图片\n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Linear(in_dim, dim * 8 * 4 * 4, bias=False),\n",
    "            nn.BatchNorm1d(dim * 8 * 4 * 4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # 2. 然后就一直反卷积，不断的将图片变大，同时通道不断减小，最终变成一个3通道，64x64大小的图片\n",
    "        self.l2 = nn.Sequential(\n",
    "            dconv_bn_relu(dim * 8, dim * 4),\n",
    "            dconv_bn_relu(dim * 4, dim * 2),\n",
    "            dconv_bn_relu(dim * 2,dim),\n",
    "            nn.ConvTranspose2d(dim, 3, 5, 2, padding = 2, output_padding = 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.l1(x)\n",
    "        y = y.view(y.size(0), -1, 4, 4)\n",
    "        y = self.l2_5(y)\n",
    "        return y\n",
    "        "
   ],
   "id": "50fc469b9e62ade1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    输入Shape为(N, 3, 64, 64)，即N张64x64的彩色图片\n",
    "    输出Shape为(N,), 即这N个图片每张图片的真实率，越接近1表示Discriminator越觉得它是真的\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim = 3, dim = 4):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        def conv_bn_lrelu(in_dim, out_dim):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_dim, out_dim, 5, 2, 2),\n",
    "                nn.BatchNorm2d(out_dim),\n",
    "                nn.LeakyReLU(0, 2)\n",
    "            )\n",
    "        \n",
    "        self.ls = nn.Sequential(\n",
    "            nn.Conv2d(in_dim, dim, 5, 2, 2),\n",
    "            nn.LeakyReLU(0, 2),\n",
    "            conv_bn_lrelu(dim, dim * 2),\n",
    "            conv_bn_lrelu(dim * 2, dim * 4),\n",
    "            conv_bn_lrelu(dim * 4, dim * 8),\n",
    "            nn.Conv2d(dim * 8, 1, 4),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.ls(x)\n",
    "        y = y.view(-1)\n",
    "        return y"
   ],
   "id": "1340886ead29dc55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "G = Generator(in_dim = z_dim)\n",
    "D = Discriminator()\n",
    "G = G.to(device)\n",
    "D = D.to(device)"
   ],
   "id": "e408bf9e763ef7af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "criterion = nn.BCELoss()",
   "id": "9821e24e2faf9dda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "opt_D = torch.optim.Adam(D.parameters(), lr = learning_rate)\n",
    "opts_G = torch.optim.Adam(G.parameters(), lr = learning_rate)"
   ],
   "id": "6b1a470ec6f125ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 训练模型",
   "id": "1faf25432a64649e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "writer = SummaryWriter()",
   "id": "103811f9c0e81327",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ],
   "id": "2020e1e6e23eb4b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import time\n",
    "time.sleep(10)"
   ],
   "id": "a1de9a4d61a897bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "开始训练",
   "id": "86cf05578a4d029"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "steps = 0\n",
    "log_after_step = 50 # 多少步记录一次Loss\n",
    "\n",
    "# 用于评估阶段的z向量\n",
    "z_sample = Variable(torch.randn(100, z_dim)).to(device)\n",
    "\n",
    "for e, epoch in enumerate(range(n_epoch)):\n",
    "    total_loss_D = 0\n",
    "    total_loss_G = 0\n",
    "\n",
    "    for i, data in enumerate(tqdm(dataloader, desc='Epoch {}: '.format(e))):\n",
    "        imgs = data\n",
    "        imgs = imgs.to(device)\n",
    "\n",
    "        # 重新获取batch_size，因为到最后一组的时候，可能凑不够\n",
    "        batch_size = imgs.size(0)\n",
    "\n",
    "        # ============================================\n",
    "        #  训练Discriminator\n",
    "        # ============================================\n",
    "        # 1. 得到一批随机的噪音向量 z\n",
    "        z = Variable(torch.randn(batch_size, z_dim)).to(device)\n",
    "        # 2. 得到真实(real)的图片\n",
    "        r_imgs = Variable(imgs).to(device)\n",
    "        # 3. 使用 Generator生成一批假(fake)图片\n",
    "        f_imgs = G(z)\n",
    "\n",
    "        # 构建标签，真实图片的标签都为1，假图片的标签都为0\n",
    "        r_label = torch.ones((batch_size, )).to(device)\n",
    "        f_label = torch.zeros((batch_size, )).to(device)\n",
    "\n",
    "        # 用Discriminator对真实图片和假图片进行判别\n",
    "        r_logit = D(r_imgs.detach())\n",
    "        f_logit = D(f_imgs.detach())\n",
    "\n",
    "        # 计算Discriminator的损失\n",
    "        r_loss = criterion(r_logit, r_label)\n",
    "        f_loss = criterion(f_logit, f_label)\n",
    "        loss_D = (r_loss + f_loss) / 2\n",
    "        total_loss_D += loss_D\n",
    "\n",
    "        # 对Discriminator进行反向传播\n",
    "        D.zero_grad()\n",
    "        loss_D.backward()\n",
    "        opt_D.step()\n",
    "\n",
    "        # ============================================\n",
    "        # 训练Generator\n",
    "        # ============================================\n",
    "        # 1. 生成N张假图片\n",
    "        z = Variable(torch.randn(batch_size, z_dim)).to(device)\n",
    "        f_imgs = G(z)\n",
    "\n",
    "        # 2. 让Discriminator判别这些假图片\n",
    "        f_logit = D(f_imgs)\n",
    "\n",
    "        # 3. 计算损失，这里Generator是希望图片越真越好，所以参数是f_logit和r_label\n",
    "        loss_G = criterion(f_logit, r_label)\n",
    "        total_loss_G += loss_G\n",
    "\n",
    "        # 对Generator进行反向传播\n",
    "        G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        opts_G.step()\n",
    "\n",
    "        steps += 1\n",
    "\n",
    "        if steps % log_after_step == 0:\n",
    "            writer.add_scalars(\"loss\", {\n",
    "                \"Loss_D\": total_loss_D / log_after_step,\n",
    "                \"Loss_G\": total_loss_G / log_after_step\n",
    "            }, global_step=steps)\n",
    "\n",
    "    # 清理之前的输出\n",
    "    clear_output()\n",
    "\n",
    "    # 每一个epoch后，生成一张一组图片看看效果\n",
    "    G.eval()\n",
    "\n",
    "    # 用Generator生成图片，并进行去除标准化，然后保存到logs目录下\n",
    "    f_imgs_sample = (G(z_sample).data + 1) / 2.0\n",
    "    if not os.path.exists('logs'):\n",
    "        os.makedirs('logs')\n",
    "    filename = os.path.join('logs', f'Epoch_{epoch + 1:03d}.jpg')\n",
    "    # 将生成的图片保存下来\n",
    "    torchvision.utils.save_image(f_imgs_sample, filename, nrow=10)\n",
    "    print(f' | Save some samples to {filename}.')\n",
    "\n",
    "    # 展示一下生成的图片\n",
    "    grid_img = torchvision.utils.make_grid(f_imgs_sample.cpu(), nrow=10)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(grid_img.permute(1, 2, 0))\n",
    "    plt.show()\n",
    "\n",
    "    # Tensorboard记录一下生成的图片\n",
    "    writer.add_image(\"Generated_Images\", grid_img, global_step=steps)\n",
    "\n",
    "    # 将Generator重新调整为训练模式\n",
    "    G.train()\n",
    "\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.makedirs(ckpt_dir)\n",
    "    # 每5个epoch保存一次模型\n",
    "    if (e + 1) % 5 == 0 or e == 0:\n",
    "        # Save the checkpoints.\n",
    "        torch.save(G.state_dict(), os.path.join(ckpt_dir, 'G_{}.pth'.format(steps)))\n",
    "        torch.save(D.state_dict(), os.path.join(ckpt_dir, 'D_{}.pth'.format(steps)))"
   ],
   "id": "adb287bc0cd47c87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "# 模型使用",
   "id": "701b0399e653c950",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "G.eval()\n",
    "inputs = torch.rand(1, 100).to(device)\n",
    "outputs = G(inputs)\n",
    "outputs = (outputs.data + 1) / 2.0\n",
    "plt.figure(figsize = (5, 5))\n",
    "plt.imshow(outputs[0].cpu().permute(1, 2, 0))\n",
    "plt.show()"
   ],
   "id": "c63c85eaf1bb77c8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python(ML)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
